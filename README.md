# Variational Autoencoder (VAE) & Deep Convolutional GAN (DCGAN)
### Generative Deep Learning for Synthetic Medical Image Generation using PyTorch

---

## ğŸ§  Overview
This repository explores two foundational **deep generative models** â€”  
a **Variational Autoencoder (VAE)** and a **Deep Convolutional GAN (DCGAN)** â€”  
trained on the **MedMNIST BloodMNIST** dataset to generate synthetic medical images.

The goal of this project is to understand how **probabilistic (VAE)** and **adversarial (GAN)** learning frameworks differ in:
- Representation learning  
- Image reconstruction quality  
- Training dynamics and stability  

Both models were implemented **from scratch** using **PyTorch**, without using pre-built architectures.

---

## âš™ï¸ Models

### ğŸ”¹ Variational Autoencoder (VAE)
**Objective:**  
Learn a latent representation of images and reconstruct them by minimizing **reconstruction loss + KL-divergence**.

**Architecture:**
- Encoder: 2 convolutional layers â†’ linear layers for Î¼ and Ïƒ  
- Latent Sampling: Reparameterization trick (Î¼ + Ïƒ * Îµ)  
- Decoder: Linear â†’ transposed convolutions to reconstruct the image  
- Activation: ReLU in hidden layers, Sigmoid in output  

**Key Insight:**  
VAEs produce *blurry but semantically meaningful* images due to their probabilistic nature.

### ğŸ”¹ Deep Convolutional GAN (DCGAN)
**Objective:**  
Generate realistic images using a **minimax adversarial game** between:
- **Generator (G):** Learns to synthesize fake images  
- **Discriminator (D):** Learns to distinguish real from fake images  

**Architecture:**
- **Generator:** ConvTranspose2d + BatchNorm + ReLU layers  
- **Discriminator:** Conv2d + BatchNorm + LeakyReLU layers  
- **Loss:** Binary Cross-Entropy (BCE) for both G and D  
- **Optimization:** Adam (Î²â‚ = 0.5, Î²â‚‚ = 0.999)

**Key Insight:**  
Training stabilizes when D(G(z)) â‰ˆ 0.5 â€” meaning the discriminator can no longer distinguish real vs. fake.

---

## ğŸ§© Dataset
- **Dataset:** [MedMNIST BloodMNIST](https://medmnist.com/)
- **Images:** 3 Ã— 64 Ã— 64 RGB blood cell images  
- **Classes:** 8 blood cell types  
- **Usage:** Only training split used (GANs donâ€™t require validation/test splits)

---

## ğŸ§° Tech Stack
| Component | Tool |
|------------|------|
| Language | Python |
| Framework | PyTorch |
| Visualization | Matplotlib |
| Dataset | MedMNIST |
| Hardware | CUDA GPU / CPU fallback |

---

## âš™ï¸ Setup

### Clone the repository
```bash
git clone https://github.com/<your-username>/vae-gan-bloodmnist.git
cd vae-gan-bloodmnist
```
## ğŸš€ Training
```bash
# Train the VAE
python train_vae.py

# Train the DCGAN
python train_gan.py
```
---

## ğŸ” Key Learnings
- Built VAE and DCGAN architectures manually in PyTorch
- Learned KL-divergence regularization and reparameterization trick
- Understood adversarial loss dynamics between Generator and Discriminator
- Applied weight initialization, normalization, and tuning for stable GAN training
- Compared latent-space behavior between probabilistic and adversarial models

---

## ğŸ“š Future Work
- Implement WGAN-GP for improved convergence
- Train Conditional GANs for class-specific generation
- Perform latent-space arithmetic and visualization
